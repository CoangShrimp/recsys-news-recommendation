import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import pandas as pd
import numpy as np
import os
import sys
import zipfile
import preprocess as pp
from model import MINDRecModel

# ==========================================
# Cáº¤U HÃŒNH (CONFIG)
# ==========================================
# TÃªn file zip (chá»‰ dÃ¹ng Ä‘á»ƒ check hoáº·c giáº£i nÃ©n náº¿u chÆ°a cÃ³ data)
ZIP_TEST_PATH = 'MINDlarge_dev.zip' 

# ThÆ° má»¥c dá»¯ liá»‡u Ä‘áº§u vÃ o (Code Colab sáº½ giáº£i nÃ©n Test set vÃ o Ä‘Ã¢y)
DIR_TEST_EXTRACTED = './mind_large_dev_data'

# ThÆ° má»¥c Train cÅ© (Ä‘á»ƒ láº¥y bá»™ tá»« Ä‘iá»ƒn)
DIR_TRAIN_DATA = 'MIND_small_train' 

# ÄÆ°á»ng dáº«n Model
MODEL_PATH = 'checkpoints/mind_model.pth'

# File káº¿t quáº£
OUTPUT_PATH = 'prediction.txt'

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def extract_data_if_needed():
    # Kiá»ƒm tra folder dá»¯ liá»‡u trÆ°á»›c
    if os.path.exists(DIR_TEST_EXTRACTED) and os.path.exists(os.path.join(DIR_TEST_EXTRACTED, 'news.tsv')):
        print(f"âœ… ÄÃ£ tÃ¬m tháº¥y dá»¯ liá»‡u táº¡i {DIR_TEST_EXTRACTED}")
        return

    # Náº¿u khÃ´ng cÃ³ folder, má»›i tÃ¬m file zip
    if not os.path.exists(ZIP_TEST_PATH):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file zip {ZIP_TEST_PATH} vÃ  cÅ©ng khÃ´ng cÃ³ folder {DIR_TEST_EXTRACTED}.")
        print("ðŸ‘‰ Vui lÃ²ng Ä‘áº£m báº£o báº¡n Ä‘Ã£ giáº£i nÃ©n dá»¯ liá»‡u Test vÃ o Ä‘Ãºng folder 'mind_large_dev_data'.")
        return
        
    try:
        print(f"ðŸ“¦ Äang giáº£i nÃ©n {ZIP_TEST_PATH}...")
        with zipfile.ZipFile(ZIP_TEST_PATH, 'r') as zip_ref:
            zip_ref.extractall(DIR_TEST_EXTRACTED)
        print(f"âœ… Giáº£i nÃ©n thÃ nh cÃ´ng.")
    except Exception as e:
        print(f"âŒ Lá»—i giáº£i nÃ©n: {e}")

def predict_one_user(model, history_str, impressions_str, news_title_matrix):
    # --- Xá»­ lÃ½ History (ThÃªm .strip() Ä‘á»ƒ trÃ¡nh lá»—i chuá»—i rá»—ng) ---
    if pd.isna(history_str):
        history_ids = []
    else:
        history_ids = str(history_str).strip().split(' ')
        
    if len(history_ids) > pp.MAX_HISTORY_LENGTH: 
        history_ids = history_ids[-pp.MAX_HISTORY_LENGTH:]
    
    # Map ID -> Vector (Náº¿u ID má»›i thÃ¬ dÃ¹ng vector 0)
    history_seqs = [news_title_matrix.get(nid, [0]*pp.MAX_TITLE_LENGTH) for nid in history_ids]
    
    # Náº¿u history rá»—ng (Cold start), thÃªm 1 vector 0 Ä‘á»ƒ trÃ¡nh lá»—i dimention
    if not history_seqs:
        history_seqs.append([0]*pp.MAX_TITLE_LENGTH)

    # Padding
    while len(history_seqs) < pp.MAX_HISTORY_LENGTH:
        history_seqs.insert(0, [0]*pp.MAX_TITLE_LENGTH)
    
    # --- Xá»­ lÃ½ Candidate (ThÃªm .strip() cá»±c ká»³ quan trá»ng) ---
    candidates = []
    impression_items = str(impressions_str).strip().split(' ')
    
    for item in impression_items:
        if not item: continue # Bá» qua item rá»—ng do lá»—i split
        # Test set format: "N12345" (khÃ´ng cÃ³ -0/-1)
        # Dev set format: "N12345-0"
        # split('-')[0] cÃ¢n Ä‘Æ°á»£c cáº£ hai
        nid = item.split('-')[0]
        candidates.append(news_title_matrix.get(nid, [0]*pp.MAX_TITLE_LENGTH))
        
    # Chuyá»ƒn sang Tensor
    history_tensor = torch.tensor([history_seqs], dtype=torch.long).to(DEVICE)
    candidate_tensor = torch.tensor(candidates, dtype=torch.long).to(DEVICE)
    
    # Inference
    with torch.no_grad():
        user_vector = model.user_encoder(history_tensor) 
        news_vectors = model.news_encoder(candidate_tensor)
        
        scores = torch.matmul(user_vector, news_vectors.t()).squeeze()
        if scores.ndim == 0:
            scores = scores.unsqueeze(0)
            
    return scores.cpu().numpy().tolist()

def main():
    # 1. Setup dá»¯ liá»‡u
    extract_data_if_needed()

    # 2. Load Tá»« Ä‘iá»ƒn (Báº¯t buá»™c tá»« Train set)
    print(f"ðŸ“– Äang load tá»« Ä‘iá»ƒn tá»« {DIR_TRAIN_DATA}...")
    if not os.path.exists(os.path.join(DIR_TRAIN_DATA, 'news.tsv')):
         raise FileNotFoundError(f"âŒ Cáº§n folder '{DIR_TRAIN_DATA}' chá»©a news.tsv (MINDsmall_train) Ä‘á»ƒ tÃ¡i táº¡o vocab.")

    df_news_train = pp.load_news_data(os.path.join(DIR_TRAIN_DATA, 'news.tsv'))
    word2index = pp.build_vocab(df_news_train['title'])
    vocab_size = len(word2index) + 1
    
    # 3. Load Dá»¯ liá»‡u Test
    print(f"ðŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u tá»« {DIR_TEST_EXTRACTED}...")
    news_path = os.path.join(DIR_TEST_EXTRACTED, 'news.tsv')
    beh_path = os.path.join(DIR_TEST_EXTRACTED, 'behaviors.tsv')
    
    if not os.path.exists(news_path) or not os.path.exists(beh_path):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u trong {DIR_TEST_EXTRACTED}.")

    df_news_dev = pp.load_news_data(news_path)
    df_beh_dev = pp.load_behaviors_data(beh_path)
    print(f"   + Sá»‘ lÆ°á»£ng logs cáº§n dá»± Ä‘oÃ¡n: {len(df_beh_dev)}")

    print("â³ Äang mÃ£ hÃ³a tiÃªu Ä‘á» bÃ i bÃ¡o...")
    news_title_matrix = {}
    # Sá»­ dá»¥ng file=sys.stdout Ä‘á»ƒ tqdm hiá»‡n mÆ°á»£t trÃªn Colab
    for nid, row in tqdm(df_news_dev.iterrows(), total=len(df_news_dev), file=sys.stdout):
        news_title_matrix[nid] = pp.transform_text(row['title'], word2index)
    
    # 4. Load Model
    print(f"ðŸ¤– Äang load model: {MODEL_PATH}...")
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y model táº¡i {MODEL_PATH}")

    model = MINDRecModel(num_words=vocab_size).to(DEVICE)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()

    # 5. Cháº¡y Predict
    print("ðŸš€ Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n...")
    with open(OUTPUT_PATH, 'w') as f:
        # Sá»­ dá»¥ng file=sys.stdout Ä‘á»ƒ tqdm hiá»‡n mÆ°á»£t trÃªn Colab
        for _, row in tqdm(df_beh_dev.iterrows(), total=len(df_beh_dev), desc="Predicting", file=sys.stdout):
            imp_id = row['impression_id']
            try:
                scores = predict_one_user(model, row['history'], row['impressions'], news_title_matrix)
                
                # Convert Score -> Rank (1, 2, 3...)
                # argsort(-scores) -> sáº¯p xáº¿p index tá»« Ä‘iá»ƒm cao xuá»‘ng tháº¥p
                sorted_indices = np.argsort(-np.array(scores))
                
                # GÃ¡n rank ngÆ°á»£c láº¡i: index cá»§a bÃ i Ä‘iá»ƒm cao nháº¥t nháº­n rank 1
                ranks = [0] * len(scores)
                for r, idx in enumerate(sorted_indices):
                    ranks[idx] = r + 1
                
                rank_str = '[' + ','.join(map(str, ranks)) + ']'
                f.write(f"{imp_id} {rank_str}\n")
                
            except Exception as e:
                # Fallback: Ä‘iá»n rank giáº£ Ä‘á»‹nh 1->N náº¿u lá»—i, Ä‘á»ƒ file khÃ´ng bá»‹ thiáº¿u dÃ²ng
                try:
                    cnt = len(str(row['impressions']).strip().split(' '))
                    fallback = list(range(1, cnt + 1))
                    f.write(f"{imp_id} {'[' + ','.join(map(str, fallback)) + ']'}\n")
                except:
                    pass

    print(f"\nðŸŽ‰ XONG! Káº¿t quáº£ lÆ°u táº¡i: {os.path.abspath(OUTPUT_PATH)}")

if __name__ == "__main__":
    main()